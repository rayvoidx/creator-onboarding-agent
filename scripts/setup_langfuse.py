"""Langfuse ì„¤ì • ë° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸"""

import asyncio
import logging
import os
import sys
from typing import Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.monitoring.langfuse import LangfuseIntegration
from src.monitoring.performance_monitor import PerformanceMonitor
from src.monitoring.metrics_collector import MetricsCollector

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LangfuseSetup:
    """Langfuse ì„¤ì • ë° í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.langfuse_integration = None
        self.performance_monitor = PerformanceMonitor()
        self.metrics_collector = MetricsCollector()
    
    async def setup_langfuse(self, config: Optional[Dict[str, Any]] = None):
        """Langfuse ì„¤ì •"""
        try:
            config = config or {
                'public_key': os.getenv('LANGFUSE_PUBLIC_KEY'),
                'secret_key': os.getenv('LANGFUSE_SECRET_KEY'),
                'host': os.getenv('LANGFUSE_HOST', 'https://cloud.langfuse.com')
            }
            
            self.langfuse_integration = LangfuseIntegration(config)
            
            # ìƒíƒœ í™•ì¸
            health_status = await self.langfuse_integration.health_check()
            
            if health_status['available'] and health_status['configured']:
                logger.info("âœ… Langfuse setup completed successfully")
                logger.info(f"   Host: {health_status['host']}")
                logger.info(f"   Connected: {health_status['connected']}")
                return True
            else:
                logger.warning("âš ï¸ Langfuse setup completed but not fully configured")
                logger.warning(f"   Available: {health_status['available']}")
                logger.warning(f"   Configured: {health_status['configured']}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Langfuse setup failed: {e}")
            return False
    
    async def test_langfuse_integration(self):
        """Langfuse í†µí•© í…ŒìŠ¤íŠ¸"""
        logger.info("Starting Langfuse integration test...")
        
        try:
            if not self.langfuse_integration:
                logger.error("Langfuse integration not initialized")
                return False
            
            # í…ŒìŠ¤íŠ¸ ì¶”ì  ì‹œì‘
            trace_id = await self.langfuse_integration.start_trace(
                name="langfuse_setup_test",
                user_id="test_user",
                session_id="test_session",
                metadata={"test_type": "setup_verification"}
            )
            
            if not trace_id:
                logger.error("Failed to start trace")
                return False
            
            logger.info(f"âœ… Trace started: {trace_id}")
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
            operation_id = await self.performance_monitor.start_operation(
                "langfuse_test_operation",
                {"test": "integration"}
            )
            
            # ê°€ìƒ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            await asyncio.sleep(0.1)
            
            await self.performance_monitor.end_operation(
                operation_id,
                success=True,
                metadata={"test_completed": True}
            )
            
            # RAG íŒŒì´í”„ë¼ì¸ ë¡œê·¸ í…ŒìŠ¤íŠ¸
            await self.langfuse_integration.log_rag_pipeline(
                trace_id=trace_id,
                query="í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
                retrieved_documents=[
                    {"content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 1", "score": 0.9, "metadata": {"source": "test"}},
                    {"content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 2", "score": 0.8, "metadata": {"source": "test"}}
                ],
                response="í…ŒìŠ¤íŠ¸ ì‘ë‹µì…ë‹ˆë‹¤.",
                processing_time=0.5,
                metadata={"test": True}
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œê·¸ í…ŒìŠ¤íŠ¸
            await self.langfuse_integration.log_agent_execution(
                trace_id=trace_id,
                agent_name="test_agent",
                input_data={"test_input": "test"},
                output_data={"test_output": "test"},
                execution_time=0.2,
                metadata={"test": True}
            )
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸
            performance_stats = self.performance_monitor.get_performance_summary()
            await self.langfuse_integration.log_performance_metrics(
                trace_id=trace_id,
                metrics=performance_stats,
                metadata={"test": True}
            )
            
            # ì¶”ì  ì¢…ë£Œ
            await self.langfuse_integration.end_trace(
                trace_id=trace_id,
                output={"test_completed": True},
                metadata={"test_result": "success"}
            )
            
            # ë°ì´í„° í”ŒëŸ¬ì‹œ
            await self.langfuse_integration.flush()
            
            logger.info("âœ… Langfuse integration test completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Langfuse integration test failed: {e}")
            return False
    
    async def test_monitoring_systems(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        logger.info("Testing monitoring systems...")
        
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„° í…ŒìŠ¤íŠ¸
            operation_id = await self.performance_monitor.start_operation(
                "monitoring_test",
                {"test": "performance_monitor"}
            )
            
            await asyncio.sleep(0.1)
            
            await self.performance_monitor.end_operation(
                operation_id,
                success=True,
                metadata={"test": "completed"}
            )
            
            performance_summary = self.performance_monitor.get_performance_summary()
            logger.info("âœ… Performance monitor test completed")
            logger.info(f"Operations tracked: {performance_summary.get('overall_stats', {}).get('total_operations', 0)}")
            
            # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸
            system_metrics = await self.metrics_collector.collect_system_metrics()
            logger.info("âœ… Metrics collector test completed")
            logger.info(f"CPU: {system_metrics.get('cpu', {}).get('percent', 0):.1f}%")
            logger.info(f"Memory: {system_metrics.get('memory', {}).get('percent', 0):.1f}%")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Monitoring systems test failed: {e}")
            return False
    
    async def generate_test_report(self):
        """í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("Generating test report...")
        
        try:
            # Langfuse ìƒíƒœ
            langfuse_status = await self.langfuse_integration.health_check() if self.langfuse_integration else {}
            
            # ì„±ëŠ¥ í†µê³„
            performance_stats = self.performance_monitor.get_performance_summary()
            
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            system_metrics = await self.metrics_collector.collect_system_metrics()
            
            report = {
                "test_timestamp": asyncio.get_event_loop().time(),
                "langfuse_status": langfuse_status,
                "performance_stats": performance_stats,
                "system_metrics": system_metrics,
                "recommendations": self._generate_recommendations(langfuse_status, performance_stats)
            }
            
            # ë¦¬í¬íŠ¸ ì¶œë ¥
            self._print_report(report)
            
            return report
            
        except Exception as e:
            logger.error(f"Failed to generate test report: {e}")
            return {}
    
    def _generate_recommendations(self, langfuse_status: Dict[str, Any], performance_stats: Dict[str, Any]) -> list:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # Langfuse ì„¤ì • í™•ì¸
        if not langfuse_status.get('configured', False):
            recommendations.append("Langfuse API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš” (LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY)")
        
        if not langfuse_status.get('connected', False):
            recommendations.append("Langfuse ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
        
        # ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­
        overall_stats = performance_stats.get('overall_stats', {})
        if overall_stats.get('overall_error_rate', 0) > 0.1:
            recommendations.append("ì—ëŸ¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ í™•ì¸í•˜ì„¸ìš”")
        
        avg_duration = overall_stats.get('avg_duration', 0)
        if avg_duration > 5.0:
            recommendations.append("í‰ê·  ì‘ë‹µ ì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
        
        return recommendations
    
    def _print_report(self, report: Dict[str, Any]):
        """ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "="*80)
        print("Langfuse Setup & Monitoring Test Report")
        print("="*80)
        
        # Langfuse ìƒíƒœ
        langfuse_status = report.get('langfuse_status', {})
        print("\nğŸ” Langfuse Status:")
        print(f"   Available: {langfuse_status.get('available', False)}")
        print(f"   Configured: {langfuse_status.get('configured', False)}")
        print(f"   Connected: {langfuse_status.get('connected', False)}")
        print(f"   Host: {langfuse_status.get('host', 'N/A')}")
        
        # ì„±ëŠ¥ í†µê³„
        performance_stats = report.get('performance_stats', {})
        overall_stats = performance_stats.get('overall_stats', {})
        print("\nğŸ“Š Performance Statistics:")
        print(f"   Total Operations: {overall_stats.get('total_operations', 0)}")
        print(f"   Error Rate: {overall_stats.get('overall_error_rate', 0):.2%}")
        print(f"   Average Duration: {overall_stats.get('avg_duration', 0):.3f}s")
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        system_metrics = report.get('system_metrics', {})
        print("\nğŸ’» System Metrics:")
        print(f"   CPU: {system_metrics.get('cpu', {}).get('percent', 0):.1f}%")
        print(f"   Memory: {system_metrics.get('memory', {}).get('percent', 0):.1f}%")
        print(f"   Disk: {system_metrics.get('disk', {}).get('percent', 0):.1f}%")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = report.get('recommendations', [])
        if recommendations:
            print("\nğŸ’¡ Recommendations:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
        else:
            print("\nâœ… All systems are properly configured!")
        
        print("="*80)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup = LangfuseSetup()
    
    try:
        # Langfuse ì„¤ì •
        langfuse_configured = await setup.setup_langfuse()
        
        # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        monitoring_success = await setup.test_monitoring_systems()
        
        # Langfuse í†µí•© í…ŒìŠ¤íŠ¸ (ì„¤ì •ëœ ê²½ìš°ì—ë§Œ)
        langfuse_test_success = True
        if langfuse_configured:
            langfuse_test_success = await setup.test_langfuse_integration()
        
        # í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
        report = await setup.generate_test_report()
        
        # ìµœì¢… ê²°ê³¼
        if langfuse_configured and monitoring_success and langfuse_test_success:
            logger.info("ğŸ‰ All tests completed successfully!")
        else:
            logger.warning("âš ï¸ Some tests failed. Check the report for details.")
        
        return report
        
    except Exception as e:
        logger.error(f"Setup failed: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
